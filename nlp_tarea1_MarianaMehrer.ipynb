{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "# Tarea 1: Classificaton Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta tarea consiste en desarrollar por vuestra cuenta un modelo de *Text-Classification*. En clase ya hemos visto este caso de uso y deber铆a resultaros sencilla la transici贸n. En cualquier caso, esta vez trabajar茅is solos. Prestad atenci贸n a todos los pasos y no dud茅is en utilizar cualquier recurso para investigar.  \n",
    "\n",
    "El dataset est谩 seleccionado al comienzo del notebook. Sin embargo, la elecci贸n, configuraci贸n y entrenamiento del modelo es totalmente libre. No olvid茅is que el notebook tiene que estar entregado con todas las celdas ejecutadas y sin errores, incluidas las celdas de evaluaci贸n al final del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: False\n",
      "CUDA version: None\n",
      "Number of GPUs available: 0\n",
      "WARNING:tensorflow:From C:\\Users\\Mariana\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mariana\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: '__init_subclass__' (from 'transformers.agents.tools') is deprecated and will be removed from version '4.51.0'. Switch to smolagents instead, with the same functionalities and similar API (https://huggingface.co/docs/smolagents/index)\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Librer铆as\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "import torch\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "\n",
    "from time import time\n",
    "from datasets import *\n",
    "from transformers import *\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvhTfthoTfFW"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "El split **MNLI** del dataset **GLUE** consiste en un par de oraciones (premisa e hip贸tesis) y una etiqueta indicando la relaci贸n entre ellas:\n",
    "\n",
    "- _Entailment_: La hip贸tesis es una conclusi贸n l贸gica de la premisa.\n",
    "- _Neutral_: La hip贸tesis no puede ser determinada como verdadera o falsa basada en la premisa.\n",
    "- _Contradiction_: La hip贸tesis contradice la premisa.\n",
    "\n",
    "Adem谩s, este split contiene diferentes subconjuntos. Principalmente, usaremos el de _train_ para entrenar y los de _validation_ para evaluar la calidad del modelo. Los de _test_ los omitiremos para este trabajo.\n",
    "- _Train_: Dataset que usaremos para entrenar el modelo.\n",
    "- _MNLI-matched_ (MNLI-m): Dataset de validaci贸n creado a partir de las mismas categor铆as de los del conjunto de entrenamiento (e.g., noticias, ficci贸n).\n",
    "- _MNLI-mismatched_ (MNLI-mm): Dataset de validaci贸n creado a partir de diferentes categor铆as de los del conjunto de entrenamiento (e.g., discursos pol铆ticos, cartas).\n",
    "\n",
    "Aqu铆 la ficha del dataset para que pod谩is explorarla: https://huggingface.co/datasets/nyu-mll/glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_AY1ATSIrIq",
    "outputId": "9a907286-7557-4c78-daa2-b6a8d5ce6938"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "    test_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9796\n",
       "    })\n",
       "    test_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9847\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No modificar esta celda\n",
    "# Esta celda, celda tiene que estar ejecutada en la entrega\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"mnli\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el 煤nico motivo de no demorar los tiempos de entrenamiento. Filtraremos el dataset y nos quedaremos solo con los registros que tenga longitud del campo _premise_ inferior a 20. \n",
    "\n",
    "El resto de la pr谩ctica se pide trabajarla sobre la variable `dataset` ya filtrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574,
     "referenced_widgets": [
      "9e670f110c794af8b3045c6261f00ea7",
      "a72f09ce216340969e6e0d91b79d2959",
      "b0d8d85d7c6d43c8ad8bf5c4ee57f49d",
      "7ca60914f7ba440f9b5a2390007e67b2",
      "4c0224089907446aa94390bcbaf9700f",
      "f6f97085fa23441087f442f64e9cc671",
      "c770318ca4b3402281226aceac1a937a",
      "be7e1df722d54c648168e15e5bfd01d5",
      "b8047c00b1644926a97542e15b0442ba",
      "256251e96d4548b7a55deed2cd053390",
      "dafb3d99c1f048d487be3e60fd777483",
      "8b5db2a6bf8b48069aa76d13cf019fa8",
      "4529e668e4a344048d551cf9e3221b15",
      "0a4cc04f53b547f38b64b3cfe11dcb29",
      "9dd30503d50441b4b1600a6124ca5c64",
      "8aca4bffd86c4ea3b7062eb5a3de078e",
      "36a45abb7f434cda96cdd19cf4f3a646",
      "dd188ec8d1234277ad1dda2bbc5c069c",
      "68e90016a797494eb6ff29ad8550553b",
      "54d6122a35ca4f578fffc09dbab1225a",
      "6199140e525c4d18a957f13b492dc3f6",
      "c2e151b03b1347cf9d9cbf889f1fd8aa",
      "f264df75cbf5453a90ab5f8f34be7e85",
      "9a92b4c7ff6449a5a74bb72064587ee4",
      "cc0bfc42e45143e28509865dcb3722e0",
      "980333d20a6f4c3ab2b5c196f82d5afd",
      "d49dc40279f04584978865eb2d0dff90",
      "b73b749940cc42f39c866432514fec3b",
      "8823728956b841408a883865681339f3",
      "c5a42806f0824c18926e7f7aa3f9f731",
      "e7857de03cfa4c028526a06a63838a72",
      "6a6eccb2ecc345a0b5a000375454e967",
      "78949868540343ab93676036e3dd33a6",
      "026c265003dd45aba4633ce6becac9d7",
      "dbfd2549cd8b4e66a6c43b7d18e47961",
      "115d02046e234a7992cd12dfcef0ed3b",
      "d0327d636fac435d9178652986870216",
      "10528b9d94064ddcb87373f9256b41e1",
      "dfb2cfdd9fee43fd8aa8e7a22fac0930",
      "fc9f4f595e4d43d1852747d96c1e0dc7",
      "f36bbdb167dd492bacf5f68aed2b40ce",
      "c2054135e3ac4001a7036383ef402510",
      "4939b6a6e5414e41a56106ec46fb1ce0",
      "7a4482a082b043f9b059d47300a8629d",
      "4d7568f34cad45c9baf8a52333684685",
      "ef9db714099a46d4a8c7618635a02765",
      "61c3a72f57064b3bb5d44f23b45d4a0b",
      "169c3bb6b4444d5a9c48bdbba8961853",
      "d7440ceab42746bc8f8ce35393d5b1a8",
      "a2401273ba8e4d65851a37e0a1acd62a",
      "80f096b7f0fb4996b2b15458f89e55ea",
      "3a1c88b5758041758b7022d5260d0635",
      "ace98ee001c94c27a46017687eb2ae0f",
      "b2a4b894afd2490797924a4f250c2970",
      "d93348b82160483c819249c04d8625a2"
     ]
    },
    "id": "X6HrpprwIrIz",
    "outputId": "64fffe2c-7b6c-4720-be65-ae70bb7ec67a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 13635\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 413\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 296\n",
       "    })\n",
       "    test_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 382\n",
       "    })\n",
       "    test_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No modificar esta celda\n",
    "# Esta celda, celda tiene que estar ejecutada en la entrega\n",
    "\n",
    "def filter_rows(x):\n",
    "    return len(x['premise'])<20\n",
    "dataset = dataset.filter(filter_rows)\n",
    "\n",
    "assert len(dataset['train']) == 13635\n",
    "assert len(dataset['validation_matched']) == 413\n",
    "assert len(dataset['validation_mismatched']) == 296\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPepm7npTfFZ"
   },
   "source": [
    "## Modeling\n",
    "\n",
    "En este apartado es donde tendr茅is que realizar todo el trabajo de la pr谩ctica. El formato, el an谩lisis, el modelo escogido y cualquier proceso intermedio que consider茅is es totalmente libre. Sin embargo, hay algunas pautas que tendr茅is que cumplir:\n",
    "\n",
    "- La variable `model_checkpoint` debe almacenar el nombre del modelo y el tokenizador de  que vais a utilizar.\n",
    "- La variable `model` y la variable `tokenizer` almacenar谩n, respectivamente, el modelo y el tokenizador de  que vais a utilizar.\n",
    "- La variable `trainer` almacenar谩 el _Trainer_ de  que, en la siguiente secci贸n utilizar茅is para entrenar el modelo.\n",
    "- Debe existir una funci贸n llamada `preprocess_function` que realice la tokenizaci贸n y, si lo consider谩is oportuno, transformaciones de las _features_.\n",
    "\n",
    "Nota: En el _tokenizer_, es obligatorio que su salida sean **tensores** de pytorch.\n",
    "\n",
    "**Importante**\n",
    "No est谩 permitido utilizar modelos pre-entrenados de Huggingface que han sido ya entrenados con este dataset, `GLUE MNIST`. Por ejemplo, no se permitir铆a usar `deberta-large-mnli`, `roberta-base-MNLI`, `glue_sst_classifier`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = None\n",
    "tokenizer = None\n",
    "model = None\n",
    "\n",
    "def preprocess_function(x):\n",
    "    return x\n",
    "\n",
    "trainer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "uNx5pyRlIrJh",
    "outputId": "a905308d-34ec-4332-ffe3-aad97bdb8d5d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# No modificar esta celda\n",
    "# Esta celda, celda tiene que estar ejecutada en la entrega\n",
    "\n",
    "assert len(trainer.train_dataset) == 13635\n",
    "\n",
    "start = time()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "end = time()\n",
    "print(f\">>>>>>>>>>>>> elapsed time: {(end-start)/60:.0f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modificar esta celda\n",
    "# Esta celda, celda tiene que estar ejecutada en la entrega\n",
    "\n",
    "print(f\"**** EVALUACIN ****\")\n",
    "print(f\"********\\nTokenizer config:\\n{tokenizer}\")\n",
    "print(f\"\\n\\n********\\nModel config:\\n{model.config}\")\n",
    "print(f\"\\n\\n********\\nTrainer arguments:\\n{trainer.args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modificar esta celda\n",
    "# Esta celda, celda tiene que estar ejecutada en la entrega\n",
    "\n",
    "sample = dataset['validation_matched'][0]\n",
    "inputs = preprocess_function(sample)\n",
    "for key, value in inputs.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"{key} es una instancia de torch.Tensor\")\n",
    "    else:\n",
    "        print(f\"{key} no es una instancia de torch.Tensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modificar esta celda\n",
    "# Esta celda, celda tiene que estar ejecutada en la entrega\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "def predict(x):\n",
    "    inputs = preprocess_function(x)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        return {'prediction': predictions.item()}\n",
    "\n",
    "ds_predictions = dataset.map(predict)\n",
    "\n",
    "assert len(ds_predictions['train']) == 13635\n",
    "assert len(ds_predictions['validation_matched']) == 413\n",
    "assert len(ds_predictions['validation_mismatched']) == 296\n",
    "\n",
    "ds_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modificar esta celda\n",
    "# Esta celda, celda tiene que estar ejecutada en la entrega\n",
    "\n",
    "for subset in ['train', 'validation_matched', 'validation_mismatched']:\n",
    "    y_true = ds_predictions[subset]['label']\n",
    "    y_pred = ds_predictions[subset]['prediction']\n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    print(f\"*** {subset} ***\")\n",
    "    ConfusionMatrixDisplay(cm).plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# No modificar esta celda\n",
    "# Esta celda, celda tiene que estar ejecutada en la entrega\n",
    "\n",
    "metrics = {}\n",
    "for subset in ['train', 'validation_matched', 'validation_mismatched']:\n",
    "    y_true = ds_predictions[subset]['label']\n",
    "    y_pred = ds_predictions[subset]['prediction']\n",
    "    acc = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    pre = precision_score(y_true=y_true, y_pred=y_pred, average=None)\n",
    "    rec = recall_score(y_true=y_true, y_pred=y_pred, average=None)\n",
    "    metrics[subset] = [acc] + pre.tolist() + rec.tolist()\n",
    "    print(f\"Subset: {subset}:\")\n",
    "    print(f\"Accuracy: {acc:.2f} | Precision0: {pre[0]:.2f} | Precision1: {pre[1]:.2f} | Precision2: {pre[2]:.2f} | Recall0: {rec[0]:.2f} | Recall1: {rec[1]:.2f} | Recall2: {rec[2]:.2f}\")\n",
    "    print(\"-----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterio de evaluaci贸n\n",
    "\n",
    "La **nota final de la tarea1** estar谩 relacionada con el resultado de las m茅tricas de vuestro modelo en la combinaci贸n de *accuracy*, *precision* y *recall* para cada _split_ de datos. \n",
    "\n",
    "El criterio de evaluaci贸n ser谩 el siguiente:\n",
    "- La tarea1 se aprobar谩 si el notebook se entrega sin fallos y con un modelo entrenado (independientemente de sus m茅tricas). \n",
    "- La tarea1 tiene un 10 si se cumple que las m茅tricas de vuestro modelo entrenado igualan o superan los siguientes umbrales:\n",
    "\n",
    "| Subset               | Accuracy | Precision0 | Precision1 | Precision2 | Recall0 | Recall1 | Recall2 |\n",
    "|----------------------|----------|------------|------------|------------|---------|---------|---------|\n",
    "| validation_matched    | 0.78     | 0.78       | 0.76       | 0.85       | 0.80    | 0.77    | 0.81    |\n",
    "| validation_mismatched | 0.79     | 0.70       | 0.70       | 0.70       | 0.65    | 0.71    | 0.85    |\n",
    "\n",
    "- Por cada valor inferior a dicha m茅trica, la tarea pierde 0.5 puntos (m谩ximo 5.0 puntos de p茅rdida).\n",
    "\n",
    "Nota: La nota que se calcula a continuaci贸n es orientativa y podr铆a verse reducida en funci贸n del c贸digo de la entrega. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modificar esta celda\n",
    "# Esta celda, celda tiene que estar ejecutada en la entrega\n",
    "\n",
    "def calculo_nota(metric):\n",
    "\n",
    "    vm_acc = float(metric['validation_matched'][0])\n",
    "    vm_pre0 = float(metric['validation_matched'][1])\n",
    "    vm_pre1 = float(metric['validation_matched'][2])\n",
    "    vm_pre2 = float(metric['validation_matched'][3])\n",
    "    vm_rec0 = float(metric['validation_matched'][4])\n",
    "    vm_rec1 = float(metric['validation_matched'][5])\n",
    "    vm_rec2 = float(metric['validation_matched'][6])\n",
    "    vmm_acc = float(metric['validation_mismatched'][0])\n",
    "    vmm_pre0 = float(metric['validation_mismatched'][1])\n",
    "    vmm_pre1 = float(metric['validation_mismatched'][2])\n",
    "    vmm_pre2 = float(metric['validation_mismatched'][3])\n",
    "    vmm_rec0 = float(metric['validation_mismatched'][4])\n",
    "    vmm_rec1 = float(metric['validation_mismatched'][5])\n",
    "    vmm_rec2 = float(metric['validation_mismatched'][6])\n",
    "\n",
    "    thresholds = {\n",
    "        'vm_acc': 0.78, 'vm_pre0': 0.78, 'vm_pre1': 0.76, 'vm_pre2': 0.85,\n",
    "        'vm_rec0': 0.80, 'vm_rec1': 0.77, 'vm_rec2': 0.81,\n",
    "        'vmm_acc': 0.79, 'vmm_pre0': 0.70, 'vmm_pre1': 0.70, 'vmm_pre2': 0.70,\n",
    "        'vmm_rec0': 0.65, 'vmm_rec1': 0.71, 'vmm_rec2': 0.85,\n",
    "    }\n",
    "    values = {\n",
    "        'vm_acc': vm_acc, 'vm_pre0': vm_pre0, 'vm_pre1': vm_pre1, 'vm_pre2': vm_pre2,\n",
    "        'vm_rec0': vm_rec0, 'vm_rec1': vm_rec1, 'vm_rec2': vm_rec2,\n",
    "        'vmm_acc': vmm_acc, 'vmm_pre0': vmm_pre0, 'vmm_pre1': vmm_pre1, 'vmm_pre2': vmm_pre2,\n",
    "        'vmm_rec0': vmm_rec0, 'vmm_rec1': vmm_rec1, 'vmm_rec2': vmm_rec2,\n",
    "    }\n",
    "\n",
    "    nota = 10\n",
    "    for key in thresholds:\n",
    "        if values[key] < thresholds[key]:\n",
    "            nota -= 0.5\n",
    "    return max(nota, 5.0)\n",
    "\n",
    "print(f\"Tu nota de la tarea1 es: {calculo_nota(metrics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
